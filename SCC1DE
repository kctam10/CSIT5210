from keras.datasets import mnist
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow.keras.backend as K
from tensorflow.keras import layers

(X_train, Y_train), (X_test, Y_test) = mnist.load_data()
X_train = X_train.astype('float32')/255
X_test = X_test.astype('float32')/255
Y_train = Y_train.astype('float32')/255
Y_test = Y_test.astype('float32')/255
input_img= Input(shape=(28,28,1))

# convolution layer
convo = layers.Conv2D(32, (3, 3), activation='relu')(input_img)
convo = layers.BatchNormalization()(convo)
convo = layers.MaxPooling2D((2, 2), padding='same')(convo)
convo = layers.Dropout(0.50)(convo)
convo = layers.Flatten()(convo)

# deep autoencoder
encoded = Dense(units=500, activation='relu')(convo) #may reduce the # of units
encoded = Dense(units=1000, activation='relu')(encoded) #may reduce the # of units
encoded = Dense(units=10, activation='relu')(encoded) 
decoded = Dense(units=1000, activation='relu')(encoded) #may reduce the # of units
decoded = Dense(units=500, activation='relu')(decoded) #may reduce the # of units
decoded = Dense(units=784, activation='sigmoid')(decoded)
decoded = layers.Reshape((28,28), input_shape=(784,))(decoded)

autoencoder=Model(input_img, decoded)
encoder = Model(input_img, encoded)

def sse(y_true, y_pred):
    return K.sum(K.square(y_pred-y_true),axis=-1)

#3s 6ms/step - loss: 0.3774 - accuracy: 0.2889 - val_loss: 0.4124 - val_accuracy: 0.2834
autoencoder.compile(optimizer='adam', loss=sse, metrics=['accuracy'])
autoencoder.fit(X_train, X_train, epochs=50, batch_size=128, 
                shuffle=True, validation_data=(X_test, X_test))

encoded_imgs = encoder.predict(X_test)
predicted = autoencoder.predict(X_test)
predicted = predicted.reshape(len(predicted), np.prod(predicted.shape[1:]))

plt.figure(figsize=(40, 4))
for i in range(10):
    # display original images
    ax = plt.subplot(3, 20, i + 1)
    plt.imshow(X_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    
    ax = plt.subplot(3, 20, 2*20 +i+ 1)
    plt.imshow(predicted[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    
plt.show()


from sklearn.cluster import KMeans
from sklearn.cluster import SpectralClustering
from sklearn.metrics.cluster import normalized_mutual_info_score

(x_train, y_train), (x_test, y_test) = mnist.load_data()
X = x_train
Y = y_train
X = X.astype(float) / 255.


L = encoder.predict(X[:5000])
K = autoencoder.predict(X[:5000])

L = L.reshape(len(L),-1)
K = K.reshape(len(K),-1)

km1 = KMeans(n_clusters=10).fit(L)
km2 = KMeans(n_clusters=10).fit(K)

print("DE+KMeans")
print(normalized_mutual_info_score(Y[:5000],km1.labels_))
print("Output+KMeans")
print(normalized_mutual_info_score(Y[:5000],km2.labels_))
#DE+KMeans
#0.6896460681583751
#Output+KMeans
#0.5044046237316591
